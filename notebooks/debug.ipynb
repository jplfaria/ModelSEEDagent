{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5535e987-eb8f-49ef-8467-7985b67d3a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.config.settings:Successfully loaded configuration from /Users/jplfaria/repos/ModelSEEDagent_v2/config/config.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug - argo_config: {'llm_name': 'gpt35', 'api_base': 'https://apps.inside.anl.gov/argoapi/api/v1/resource/chat/', 'user': 'jplfaria', 'system_content': 'You are an AI assistant specialized in metabolic modeling.'}\n",
      "Debug - Config validation...\n",
      "Debug - LLM created\n",
      "Debug - LLM attributes: ['InputType', 'OutputType', '__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__or__', '__orig_bases__', '__parameters__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__repr__', '__repr_args__', '__repr_name__', '__repr_str__', '__rich_repr__', '__ror__', '__setattr__', '__setstate__', '__signature__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abatch_with_config', '_abc_impl', '_acall_with_config', '_all_required_field_names', '_api_base', '_atransform_stream_with_config', '_batch_with_config', '_calculate_keys', '_call_with_config', '_calls', '_check_frozen', '_config', '_copy_and_set_values', '_format_messages_as_text', '_generate_response', '_get_value', '_identifying_params', '_is_protocol', '_iter', '_llm_type', '_tokens', '_transform_stream_with_config', '_user', 'abatch', 'abatch_as_completed', 'agenerate_prompt', 'ainvoke', 'api_base', 'apredict', 'apredict_messages', 'as_tool', 'assign', 'astream', 'astream_events', 'astream_log', 'atransform', 'batch', 'batch_as_completed', 'bind', 'cache', 'callbacks', 'check_limits', 'config', 'config_schema', 'config_specs', 'configurable_alternatives', 'configurable_fields', 'construct', 'copy', 'custom_get_token_ids', 'dict', 'estimate_tokens', 'from_orm', 'generate_prompt', 'get_config_jsonschema', 'get_graph', 'get_input_jsonschema', 'get_input_schema', 'get_lc_namespace', 'get_name', 'get_num_tokens', 'get_num_tokens_from_messages', 'get_output_jsonschema', 'get_output_schema', 'get_prompts', 'get_token_ids', 'input_schema', 'invoke', 'is_lc_serializable', 'json', 'lc_attributes', 'lc_id', 'lc_secrets', 'map', 'metadata', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'name', 'output_schema', 'parse_file', 'parse_obj', 'parse_raw', 'pick', 'pipe', 'predict', 'predict_messages', 'schema', 'schema_json', 'set_verbose', 'stream', 'tags', 'to_json', 'to_json_not_implemented', 'transform', 'update_forward_refs', 'update_usage', 'user', 'validate', 'verbose', 'with_alisteners', 'with_config', 'with_fallbacks', 'with_listeners', 'with_retry', 'with_structured_output', 'with_types']\n",
      "Debug - Config: llm_name='gpt35' system_content='You are an AI assistant specialized in metabolic modeling.' max_tokens=None temperature=0.7 stop_sequences=None api_base='https://apps.inside.anl.gov/argoapi/api/v1/resource/chat/' user='jplfaria' safety_settings={'enabled': True, 'max_api_calls': 100, 'max_tokens': 50000}\n",
      "Debug - Predicting...\n",
      "Response from gpt35: You can call me MetaboAI. How can I assist you today?\n",
      "\n",
      "Response from gpt4: As an AI, I don't have a personal name. However, you can refer to me as Metabolic Modeling Assistant.\n"
     ]
    }
   ],
   "source": [
    "import sys, logging\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.config.settings import load_config\n",
    "from src.llm import LLMFactory\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "config = load_config()\n",
    "\n",
    "# Debug first attempt\n",
    "model = config.argo.default_model\n",
    "argo_config = {\n",
    "    \"llm_name\": model,\n",
    "    \"api_base\": config.argo.models[model][\"api_base\"],\n",
    "    \"user\": config.argo.user,\n",
    "    \"system_content\": config.argo.system_content\n",
    "}\n",
    "\n",
    "print(\"Debug - argo_config:\", argo_config)\n",
    "print(\"Debug - Config validation...\")\n",
    "llm = LLMFactory.create(config.llm.llm_backend, argo_config)\n",
    "print(\"Debug - LLM created\")\n",
    "print(\"Debug - LLM attributes:\", dir(llm))\n",
    "print(\"Debug - Config:\", getattr(llm, '_config', None))\n",
    "\n",
    "\n",
    "# Test predictions\n",
    "user_input = \"What is your name?\"\n",
    "try:\n",
    "    print(\"Debug - Predicting...\")\n",
    "    response = llm.predict(user_input)\n",
    "    print(f\"Response from {model}:\", response)\n",
    "except Exception as e:\n",
    "    print(f\"Debug - Error: {str(e)}\")\n",
    "\n",
    "# Switch model\n",
    "model = \"gpt4\"\n",
    "argo_config.update({\n",
    "    \"llm_name\": model,\n",
    "    \"api_base\": config.argo.models[model][\"api_base\"]\n",
    "})\n",
    "llm = LLMFactory.create(config.llm.llm_backend, argo_config)\n",
    "try:\n",
    "    response = llm.predict(user_input)\n",
    "    print(f\"\\nResponse from {model}:\", response)\n",
    "except Exception as e:\n",
    "    print(f\"\\nDebug - Error with {model}:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559fe12-4ee5-40fa-841b-f9b66e14199d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
